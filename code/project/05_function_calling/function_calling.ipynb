{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "\n",
    "Read:\n",
    "\n",
    "https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client : OpenAI = OpenAI()\n",
    "print(_)\n",
    "print(type(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basic sequence of steps for function calling is as follows:\n",
    "\n",
    "1. Call the model with the user query and a set of functions defined in the functions parameter.\n",
    "2. The model can choose to call one or more functions; if so, the content will be a stringified JSON object adhering to your custom schema (note: the model may hallucinate parameters).\n",
    "3. Parse the string into JSON in your code, and call your function with the provided arguments if they exist.\n",
    "4. Call the model again by appending the function response as a new message, and let the model summarize the results back to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](first.png \"function_calling\")\n",
    "\n",
    "![Alt text](second.png \"function_calling\")\n",
    "\n",
    "https://www.linkedin.com/pulse/azure-openai-function-calling-tarun-sharma/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example dummy function hard coded to return the same weather\n",
    "# # In production, this could be your backend API or an external API\n",
    "def get_current_weather(location:str, unit:str=\"fahrenheit\")->str:\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"karachi\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Karachi\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"islamabad\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Islamabad\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"lahore\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Lahore\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location.lower(), \"temperature\": \"sorry, does not provide the temprature from your given place\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"Karachi\", \"temperature\": \"10\", \"unit\": \"celsius\"}'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(location=\"karachi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"Lahore\", \"temperature\": \"22\", \"unit\": \"celsius\"}'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(location=\"LAHORE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"tokyo\", \"temperature\": \"sorry, does not provide the temprature from your given place\"}'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(location=\"TOKYO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types\n",
    "\n",
    "https://github.com/openai/openai-python/tree/main/src/openai/types/chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* First Response: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [ChatCompletionMessageToolCall(id='call_Otm8EMWDgX2lrEblWpDDRuTH', function=Function(arguments='{\"location\": \"Lahore\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       "  ChatCompletionMessageToolCall(id='call_oRNbHAC9K96pR0pIVP3JSg98', function=Function(arguments='{\"location\": \"Karachi\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       "  ChatCompletionMessageToolCall(id='call_eYDBmZZcDOpF98YRIGyUbXWb', function=Function(arguments='{\"location\": \"Islamabad\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'* First Response Tool Calls: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_Otm8EMWDgX2lrEblWpDDRuTH', function=Function(arguments='{\"location\": \"Lahore\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='call_oRNbHAC9K96pR0pIVP3JSg98', function=Function(arguments='{\"location\": \"Karachi\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='call_eYDBmZZcDOpF98YRIGyUbXWb', function=Function(arguments='{\"location\": \"Islamabad\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'* Second Request Messages: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"What's the weather like in lahore, karachi, islamabad?\"},\n",
       " ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Otm8EMWDgX2lrEblWpDDRuTH', function=Function(arguments='{\"location\": \"Lahore\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_oRNbHAC9K96pR0pIVP3JSg98', function=Function(arguments='{\"location\": \"Karachi\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_eYDBmZZcDOpF98YRIGyUbXWb', function=Function(arguments='{\"location\": \"Islamabad\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]),\n",
       " {'tool_call_id': 'call_Otm8EMWDgX2lrEblWpDDRuTH',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '\"{\\\\\"location\\\\\": \\\\\"Lahore\\\\\", \\\\\"temperature\\\\\": \\\\\"22\\\\\", \\\\\"unit\\\\\": \\\\\"celsius\\\\\"}\"'},\n",
       " {'tool_call_id': 'call_oRNbHAC9K96pR0pIVP3JSg98',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '\"{\\\\\"location\\\\\": \\\\\"Karachi\\\\\", \\\\\"temperature\\\\\": \\\\\"10\\\\\", \\\\\"unit\\\\\": \\\\\"celsius\\\\\"}\"'},\n",
       " {'tool_call_id': 'call_eYDBmZZcDOpF98YRIGyUbXWb',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '\"{\\\\\"location\\\\\": \\\\\"Islamabad\\\\\", \\\\\"temperature\\\\\": \\\\\"72\\\\\", \\\\\"unit\\\\\": \\\\\"fahrenheit\\\\\"}\"'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Second Response:  {'id': 'chatcmpl-9XVWWGZquEvO2UU66tVpeA6cn0JwA', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Currently, the weather in Lahore is 22°C, in Karachi is 10°C, and in Islamabad is 22.2°C.', role='assistant', function_call=None, tool_calls=None))], 'created': 1717773028, 'model': 'gpt-3.5-turbo-1106', 'object': 'chat.completion', 'system_fingerprint': 'fp_482d920018', 'usage': CompletionUsage(completion_tokens=28, prompt_tokens=178, total_tokens=206)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Currently, the weather in Lahore is 22°C, in Karachi is 10°C, and in Islamabad is 22.2°C.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletionMessage, ChatCompletion\n",
    "# from openai.types.chat.chat_completion import ChatCompletionMessageParam, ChatCompletionMessageParam\n",
    "\n",
    "def run_conversation(main_request: str)->str:\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": main_request}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # First Request\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message: ChatCompletionMessage = response.choices[0].message\n",
    "    display(\"* First Response: \", dict(response_message))\n",
    "    print(\"=============================\")\n",
    "    tool_calls = response_message.tool_calls\n",
    "    display(\"* First Response Tool Calls: \", list(tool_calls))\n",
    "\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function via FastAPI\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "          if tool_call.type == \"function\":  \n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = call_fastapi_get_current_weather(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(function_response),\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        display(\"* Second Request Messages: \", list(messages))\n",
    "        second_response: ChatCompletion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        print(\"* Second Response: \", dict(second_response))\n",
    "        return second_response.choices[0].message.content\n",
    "\n",
    "# run_conversation(\"What's the weather like in lahore, karachi, and islamabad?\")\n",
    "run_conversation(\"What's the weather like in lahore, karachi, islamabad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* First Response: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [ChatCompletionMessageToolCall(id='call_ocZSvWkq7h5nHmzsECXkR1v8', function=Function(arguments='{\"location\":\"Tokyo\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'* First Response Tool Calls: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_ocZSvWkq7h5nHmzsECXkR1v8', function=Function(arguments='{\"location\":\"Tokyo\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'* Second Request Messages: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"What's the weather like in tokyo?\"},\n",
       " ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ocZSvWkq7h5nHmzsECXkR1v8', function=Function(arguments='{\"location\":\"Tokyo\",\"unit\":\"celsius\"}', name='get_current_weather'), type='function')]),\n",
       " {'tool_call_id': 'call_ocZSvWkq7h5nHmzsECXkR1v8',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '\"{\\\\\"location\\\\\": \\\\\"tokyo\\\\\", \\\\\"temperature\\\\\": \\\\\"sorry, does not provide the temperature from your given place\\\\\"}\"'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Second Response:  {'id': 'chatcmpl-9XVXCX7dznSwQ8nshVBt7wo6pFn90', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, but I'm unable to provide the current weather in Tokyo. You may want to check a reliable weather website or app for the most accurate and up-to-date information.\", role='assistant', function_call=None, tool_calls=None))], 'created': 1717773070, 'model': 'gpt-3.5-turbo-1106', 'object': 'chat.completion', 'system_fingerprint': 'fp_b953e4de39', 'usage': CompletionUsage(completion_tokens=37, prompt_tokens=72, total_tokens=109)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I'm unable to provide the current weather in Tokyo. You may want to check a reliable weather website or app for the most accurate and up-to-date information.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletionMessage, ChatCompletion\n",
    "# from openai.types.chat.chat_completion import ChatCompletionMessageParam, ChatCompletionMessageParam\n",
    "\n",
    "def run_conversation(main_request: str)->str:\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": main_request}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # First Request\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message: ChatCompletionMessage = response.choices[0].message\n",
    "    display(\"* First Response: \", dict(response_message))\n",
    "    print(\"=============================\")\n",
    "    tool_calls = response_message.tool_calls\n",
    "    display(\"* First Response Tool Calls: \", list(tool_calls))\n",
    "\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function via FastAPI\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "          if tool_call.type == \"function\":  \n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = call_fastapi_get_current_weather(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": json.dumps(function_response),\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        display(\"* Second Request Messages: \", list(messages))\n",
    "        second_response: ChatCompletion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        print(\"* Second Response: \", dict(second_response))\n",
    "        return second_response.choices[0].message.content\n",
    "\n",
    "# run_conversation(\"What's the weather like in lahore, karachi, and islamabad?\")\n",
    "run_conversation(\"What's the weather like in tokyo?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
